# PreciseVideo: A Dual-Process Framework for Zero-Shot Text-to-Video Generation with Quantitative Content Control
PreciseVideo is a **zero-shot text-to-video generation framework** that enables **precise and quantifiable control** over both background and character content. It is built upon pre-trained text-to-image diffusion models and explicitly separates **background generation** and **character generation** stages to enhance control and visual quality.

## ‚ú® Key Features

- üéØ **Dual-Stage Design**: Separates video generation into **background** and **character** stages for enhanced control and flexibility.
- üåå **Region-Wise Temporal Control**: Introduces a *latent space noise modulator* and *sparse-fusion attention* to control how much different areas in the scene change over time.
- üßç **Consistent and Complete Characters**: Proposes *optimal-reference-frame attention* to maintain **identity, appearance, and limb completeness** across frames.
- üéÆ **ControlNet Integration**: Achieves **99.51% accuracy** in aligning generated characters with specified poses or counts.
- üìä **Quantitative Temporal Control**: The  shows strong correlation with frame-wise metrics:
  - MSE: **0.93**
  - SSIM: **‚Äì0.96**
- üë• **Handles Complex Scenes**: Capable of handling:
  - Multiple interacting characters
  - Scene-to-character and person-to-person occlusions
  - Crowded environments


## üé¨ Experimental Results
We have released several original experimental results, including batch-generated videos with consecutive random seeds, to enhance transparency and reproducibility. For more comprehensive quantitative evaluations, please refer to the paper.

### 1. We are able to control the temporal variation intensity of video backgrounds. The following results demonstrate the effect of varying the temporal variation intensity (Œ¥) from left to right, with values ranging from 0 to 1 in increments of 0.1.


![If the animation does not display correctly, please refer to ./examples/bg1.gif.](./examples/bg1.gif)

### 2. Our control capability is independent across regions. In the following example, the temporal variation intensity of the "sky" region gradually decreases, while that of the "waves" region gradually increases.


![If the animation does not display correctly, please refer to ./examples/bg2.gif.](./examples/bg2.gif)


### 3. Pose Reconstruction Under Varying Motion Complexity
To validate robustness, we conducted an ablation study measuring pose reconstruction accuracy across increasing motion complexity. For each motion complexity level, videos were generated using 10 consecutive random seeds (0‚Äì9) to ensure consistency and reduce randomness. As a baseline, we replaced our module with the corresponding components from T2V-Zero. Our method consistently preserved accurate joint structures, while the baseline showed significant degradation as complexity increased. Full results are visualized below.

![If the animation does not display correctly, please refer to ./examples/bg2.gif.](./examples/character_resized.gif)



### 4. Robustness Across Diverse Motion Patterns

To further evaluate the robustness of our method, we tested it on four distinct motion categories: Tai Chi and Skiing from UCF101, as well as Yoga and Sit-ups from Kinetics. For each category, we extracted real human poses from dataset videos and used them as guidance to generate characters. All sequences were generated using 200 consecutive random seeds (0‚Äì199). Our method consistently produced characters that accurately followed the target poses, demonstrating strong generalization and stability across diverse motion patterns.Note: A few frames in two videos are overlaid with gray to mask rare NSFW content occasionally generated by the diffusion model.



![If the animation does not display correctly, please refer to ./examples/bg2.gif.](./examples/Tai_Chi_seed_0-199.gif)


![If the animation does not display correctly, please refer to ./examples/bg2.gif.](./examples/skiing_seed_0-199.gif)


![If the animation does not display correctly, please refer to ./examples/bg2.gif.](./examples/Yoga_seed_0-199.gif)


![If the animation does not display correctly, please refer to ./examples/bg2.gif.](./examples/situp_seed_0-199.gif)
